# Caso de estudio

Una aplicaci√≥n web desplegada en un cl√∫ster de Kubernetes est√° experimentando
tiempos de respuesta lentos durante los picos de tr√°fico. El despliegue actual
tiene configuradas tres r√©plicas, pero los usuarios siguen reportando problemas
de lentitud. Adem√°s, al revisar los logs, se observa que los pods est√°n alcanzando
altos niveles de uso de CPU.

## üèóÔ∏è Preparaci√≥n del entorno de pruebas y monitoreo

Para obtener informaci√≥n relevante del caso acerca del comportamiento de la aplicaci√≥n y poder evidenciar el funcionamiento de HPA es necesario haber desplegado la aplicaci√≥n con Kubernetes bajo la configuraci√≥n de Minikube, ver [***README.md***](README.md) - *3. Despliegue con Minikube*

```bash

# Activaci√≥n de los addons necesarios: metrics-server
minikube addons enable metrics-server

# Consultar los servicios activos
kubectl get all -n php-mysql # El output ser√°n 3 replicas activas de la app

# Ejecutar pruebas con Apache Bench
```
### Ejecuci√≥n de pruebas

Las pruebas podr√°n ejecutarse en sistemas unix usando la librer√≠a de Apache Bench, si cuenta con distribuci√≥n Windows se podr√° instalar XAMPP y usar la Shell incorporada a dicho sistema. 

![Ejemplo shell de xampp](./assets/xampp.png)

```bash
# Simulaci√≥n de carga
ab -n 10000 -c 100 http://localhost:8080
```


## üî¨ An√°lisis del caso
## Problemas en la configuraci√≥n de Kubernetes

### 1. Sin Resource Limits

**Archivo**: `kubernetes/deployment.yaml`
```yaml
spec:
  containers:
  - name: php-app
    image: php-app:latest
    ports:
    - containerPort: 80
    # ‚ùå SIN resources limits/requests
```

**Consecuencia**:
- Un pod puede consumir 100% CPU disponible
- Kubernetes no sabe si el pod est√° saturado
- No puede hacer eviction controlada

**Con 3 pods en minikube (2 CPUs)**:
- 1 pod consume 1.5 CPUs
- 2 pod consume 0.4 CPUs
- 3 pod = espera, cae rendimiento

---

### 2. Sin Health Checks

**Falta en deployment.yaml**:
```yaml
livenessProbe:
  httpGet:
    path: /
    port: 80
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /
    port: 80
  initialDelaySeconds: 5
  periodSeconds: 5
```

**Consecuencia**:
- Pod puede estar "vivo" pero no responda
- Kubernetes sigue enviando tr√°fico
- Conexiones pendientes se acumulan
- Timeouts de cliente

**Ejemplo**: 
- Pod A est√° en estado zombie (MySQL desconectado)
- Sigue recibiendo tr√°fico (readinessProbe falta)
- Cliente espera 30s, timeout
- Kubernetes no reinicia el pod

---

### 4. 3 R√©plicas son Insuficientes Bajo Carga

**Archivo**: `kubernetes/deployment.yaml`
```yaml
replicas: 3
```

**Con prueba de carga `ab -n 1000 -c 50`**:
- 50 requests concurrentes
- 50 √∑ 3 ‚âà 17 requests por pod
- Cada request toma ~2 segundos (sleep + queries)
- 17 √ó 2 = 34 segundos de cola
- Timeouts despu√©s de 30s

**Impacto**:
- ~40% requests fallan
- Usuarios ven "Connection refused"
- No es un problema de replicas, sino de rendimiento por pod

---

### 5. Sin Horizontal Pod Autoscaler (HPA)

**Falta completamente**:
- No hay escalado autom√°tico
- Aunque agregues replicas, el problema persiste
- Cada pod es igual de lento

**El root cause est√° en la aplicaci√≥n, no en cantidad de pods**

---

## ‚åõ Flujo de Ejecuci√≥n Lento

**Caso: Usuario accede a /usuarios con 50 concurrencias**

```
1. Request llega al Load Balancer (nginx/kube-proxy)
   ‚Üì
2. Redirige a Pod (1, 2 o 3)
   ‚Üì
3. Apache recibe, inicia PHP
   ‚Üì
4. index.php carga:
   - Loop 100,000 iteraciones sqrt: ~50ms ‚è±Ô∏è
   - Desv√≠a a pages/usuarios.php
   ‚Üì
5. usuarios.php:
   - Conexi√≥n a MySQL: ~5ms
   - SELECT * FROM usuarios: 
     * Sin √≠ndice en id: ~100ms (full scan)
   - fetch_assoc() loop: ~50ms
   - Renderiza HTML: ~50ms
   ‚Üì
6. PHP genera HTML
   ‚Üì
7. Apache env√≠a respuesta: ~20ms
   ‚Üì
8. Total: ~320ms por request

Con 50 concurrentes:
- 50 √ó 320ms = 16 segundos acumulados
- Pero solo 3 pods: 16s √∑ 3 = 5.3s por pod
- Pod bloqueado 5.3 segundos
- 50 siguiente requests esperan...
- Timeout en 30s
```

**Agregar sleep(1) en dashboard:**
```
Tiempo total: ~1320ms por request
Con 50 concurrentes: 50s de latencia
Timeout en 30s ‚Üí ~40% fallan
```

---

## ü©∫ S√≠ntomas Observables

### CPU Alta

```bash
$ kubectl top pods -n app-namespace

NAME                      CPU(cores)   MEMORY(Mi)
mysql-xxxx                150m         320Mi
php-app-yyyy              480m         95Mi      ‚ö†Ô∏è Alto
php-app-zzzz              490m         98Mi      ‚ö†Ô∏è Alto
php-app-wwww              475m         92Mi      ‚ö†Ô∏è Alto
```

**Causa**: Loop sqrt() √ó concurrencia

---

## ‚úÖ Soluci√≥n del caso

## üìã Resumen de las 3 Optimizaciones

| Optimizaci√≥n | Problema que Resuelve | Impacto |
|--------------|----------------------|---------|
| **Resource Limits** | Pods consumen todos los recursos | Kubernetes puede predecir y escalar |
| **Health Checks** | Pods "muertos" reciben tr√°fico | Solo pods saludables reciben tr√°fico |
| **HPA** | N√∫mero fijo de r√©plicas | Escala autom√°ticamente seg√∫n demanda |

---

## üéØ OPTIMIZACI√ìN 1: Resource Limits

### Qu√© Hace

Define **cu√°ntos recursos** (CPU y memoria) puede usar cada pod:
- **Requests**: Recursos garantizados m√≠nimos
- **Limits**: Recursos m√°ximos permitidos

### C√≥digo Agregado

```yaml
resources:
  requests:
    cpu: "250m"        # 0.25 cores garantizados
    memory: "128Mi"    # 128 MB garantizados
  limits:
    cpu: "500m"        # 0.5 cores m√°ximo
    memory: "256Mi"    # 256 MB m√°ximo
```

### C√≥mo Funciona

1. **Requests**: Kubernetes reserva estos recursos para el pod
2. **Limits**: Si el pod intenta usar m√°s, Kubernetes lo limita
3. **CPU**: Throttling si excede el l√≠mite
4. **Memoria**: OOMKilled si excede el l√≠mite

### Beneficios

- ‚úÖ Kubernetes sabe cu√°ntos pods caben en un nodo
- ‚úÖ Previene que un pod acapare todos los recursos
- ‚úÖ HPA puede decidir cu√°ndo escalar
- ‚úÖ Mejor distribuci√≥n de carga

### Antes vs Despu√©s

```
ANTES (Sin limits):
- Pod 1: 1.5 CPU, 512 MB  üò±
- Pod 2: 0.3 CPU, 100 MB
- Pod 3: 0.8 CPU, 200 MB
- Total: 2.6 CPU (excede cluster de 2 CPU)
- Resultado: Performance degradado

DESPU√âS (Con limits):
- Pod 1: 0.5 CPU, 256 MB ‚úÖ
- Pod 2: 0.5 CPU, 256 MB ‚úÖ
- Pod 3: 0.5 CPU, 256 MB ‚úÖ
- Total: 1.5 CPU (dentro del l√≠mite)
- Resultado: Performance predecible
```

---

## üéØ OPTIMIZACI√ìN 2: Health Checks

### Qu√© Hace

Kubernetes verifica continuamente si los pods est√°n **saludables**:
- **livenessProbe**: ¬øEst√° vivo el contenedor?
- **readinessProbe**: ¬øEst√° listo para tr√°fico?
- **startupProbe**: ¬øHa iniciado correctamente?

### C√≥digo Agregado

```yaml
# Liveness: Reinicia si falla
livenessProbe:
  httpGet:
    path: /
    port: 80
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3

# Readiness: Quita de Service si falla
readinessProbe:
  httpGet:
    path: /
    port: 80
  initialDelaySeconds: 10
  periodSeconds: 5
  failureThreshold: 3

# Startup: Protege durante inicio
startupProbe:
  httpGet:
    path: /
    port: 80
  periodSeconds: 10
  failureThreshold: 30
```

### C√≥mo Funciona

#### Liveness Probe
```
1. Cada 10s, Kubernetes hace: GET http://pod-ip/
2. Si responde 200 OK ‚Üí Pod est√° vivo ‚úÖ
3. Si falla 3 veces consecutivas ‚Üí Reiniciar pod üîÑ
```

#### Readiness Probe
```
1. Cada 5s, Kubernetes hace: GET http://pod-ip/
2. Si responde 200 OK ‚Üí Pod listo para tr√°fico ‚úÖ
3. Si falla 3 veces ‚Üí Quitar del Service ‚õî
4. Cuando vuelve a funcionar ‚Üí Reintegrar al Service ‚úÖ
```

#### Startup Probe
```
1. Durante inicio, protege al pod
2. Permite hasta 5 minutos (30 √ó 10s) para iniciar
3. Despu√©s activa liveness y readiness
```

### Beneficios

‚úÖ Pods "zombies" son reiniciados autom√°ticamente
‚úÖ Solo pods saludables reciben tr√°fico
‚úÖ No se pierde tr√°fico durante despliegues
‚úÖ Detecci√≥n temprana de problemas

### Escenario de Ejemplo

```
ANTES (Sin health checks):
1. Pod A se cae (MySQL desconectado)
2. LoadBalancer sigue enviando tr√°fico al Pod A
3. 33% de requests fallan
4. Usuario reporta el problema
5. Manual restart del pod

DESPU√âS (Con health checks):
1. Pod A se cae (MySQL desconectado)
2. readinessProbe falla 3 veces (15s)
3. Kubernetes quita Pod A del Service
4. LoadBalancer solo env√≠a a Pod B y C
5. 0% de requests fallan
6. livenessProbe falla 3 veces (30s)
7. Kubernetes reinicia Pod A autom√°ticamente
8. Pod A vuelve, readinessProbe pasa
9. Pod A reintegrado al Service
```

---

## üéØ OPTIMIZACI√ìN 3: HPA (Horizontal Pod Autoscaler)

### Qu√© Hace

Escala **autom√°ticamente** el n√∫mero de pods seg√∫n la carga:
- Monitorea CPU y memoria
- Aumenta pods cuando hay mucha carga
- Reduce pods cuando baja la carga

### C√≥digo Agregado

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: php-app-hpa
spec:
  scaleTargetRef:
    kind: Deployment
    name: php-app
  
  minReplicas: 3
  maxReplicas: 10
  
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### C√≥mo Funciona

```
1. HPA monitorea m√©tricas cada 15s (default)
2. Calcula promedio de CPU y memoria de todos los pods
3. Si promedio > 70% CPU o > 80% memoria:
   ‚Üí Aumenta pods
4. Si promedio < 70% CPU y < 80% memoria:
   ‚Üí Reduce pods (despu√©s de 5 min de estabilidad)
```

### F√≥rmula de Escalado

```
desired_replicas = ceil(current_replicas √ó (current_metric / target_metric))

Ejemplo:
- R√©plicas actuales: 3
- CPU actual: 90%
- CPU objetivo: 70%

desired_replicas = ceil(3 √ó (90 / 70)) = ceil(3.86) = 4 pods
```

### Comportamiento de Escalado

#### Scale Up (Aumentar)
```yaml
scaleUp:
  stabilizationWindowSeconds: 0    # Sin espera
  policies:
  - type: Percent
    value: 100                     # Duplica pods
    periodSeconds: 15              # En 15s
  - type: Pods
    value: 4                       # O suma 4 pods
```

**Ejemplo**: 3 pods ‚Üí 90% CPU ‚Üí +4 pods = 7 pods (en 15s)

#### Scale Down (Reducir)
```yaml
scaleDown:
  stabilizationWindowSeconds: 300  # Espera 5 min
  policies:
  - type: Percent
    value: 50                      # Reduce 50% m√°ximo
    periodSeconds: 60              # En 60s
  - type: Pods
    value: 2                       # O reduce 2 pods
```

**Ejemplo**: 7 pods ‚Üí 30% CPU ‚Üí Espera 5 min ‚Üí -2 pods = 5 pods (en 60s)

### Beneficios

‚úÖ Responde autom√°ticamente a picos de tr√°fico
‚úÖ Ahorra recursos cuando hay baja demanda
‚úÖ No necesitas intervenci√≥n manual
‚úÖ Mantiene performance consistente

### Escenario Real

```
08:00 AM - Tr√°fico bajo
‚îú‚îÄ 50 req/min ‚Üí 30% CPU
‚îú‚îÄ HPA: 3 pods (m√≠nimo)
‚îî‚îÄ Costo: Bajo

12:00 PM - Pico de almuerzo
‚îú‚îÄ 500 req/min ‚Üí 85% CPU
‚îú‚îÄ HPA detecta sobrecarga
‚îú‚îÄ Escala: 3 ‚Üí 5 ‚Üí 7 pods (en 30s)
‚îú‚îÄ CPU baja a 60%
‚îî‚îÄ Performance: Estable

02:00 PM - Tr√°fico normal
‚îú‚îÄ 200 req/min ‚Üí 50% CPU
‚îú‚îÄ HPA espera 5 min de estabilidad
‚îú‚îÄ Escala: 7 ‚Üí 5 ‚Üí 3 pods (gradualmente)
‚îî‚îÄ Costo: Optimizado

05:00 PM - Pico de tarde
‚îú‚îÄ 800 req/min ‚Üí 90% CPU
‚îú‚îÄ HPA escala: 3 ‚Üí 7 ‚Üí 10 pods (m√°ximo)
‚îî‚îÄ Performance: Mantenida
```

---

## üìä Comparaci√≥n: Antes vs Despu√©s

### M√©tricas de Impacto

| M√©trica | Sin Optimizaciones | Con Optimizaciones | Mejora |
|---------|-------------------|-------------------|--------|
| CPU por pod | 480m (ilimitado) | 250-500m (limitado) | Predecible |
| Tr√°fico a pods muertos | 33% del tiempo | 0% | 100% |
| Respuesta a picos | Manual (30+ min) | Autom√°tica (30s) | 60x m√°s r√°pido |
| Pods durante bajo tr√°fico | 3 (fijos) | 3 (m√≠nimo) | √ìptimo |
| Pods durante alto tr√°fico | 3 (fijos) | 3-10 (din√°mico) | 3.3x capacidad |
| Failed requests (carga alta) | 40% | 5% | 8x mejor |

---

## üöÄ C√≥mo Aplicar las Optimizaciones

### Paso 1: Habilitar Metrics Server (Requerido para HPA)

```bash
# En minikube
minikube addons enable metrics-server

# En clusters reales
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Verificar
kubectl top nodes
kubectl top pods -n app-namespace
```

### Paso 2: Aplicar el Deployment Optimizado

```bash
# Eliminar deployment anterior
kubectl delete deployment php-app -n app-namespace

# Aplicar optimizado
kubectl apply -f kubernetes/deployment-optimized.yaml -n app-namespace

# Verificar
kubectl get deployment php-app -n app-namespace
kubectl get hpa -n app-namespace
```

### Paso 3: Verificar Health Checks

```bash
# Ver eventos de health checks
kubectl describe pod <pod-name> -n app-namespace

# Buscar l√≠neas como:
# Liveness probe succeeded
# Readiness probe succeeded

# Ver logs de probes
kubectl logs <pod-name> -n app-namespace | grep "k8s-liveness\|k8s-readiness"
```

### Paso 4: Ver HPA en Acci√≥n

```bash
# Terminal 1: Monitorear HPA
watch 'kubectl get hpa -n app-namespace'

# Terminal 2: Generar carga
ab -n 10000 -c 100 http://localhost:8080/?action=usuarios

# Terminal 3: Ver pods escalando
watch 'kubectl get pods -n app-namespace'

# Observar√°s:
# - HPA muestra CPU subiendo
# - Nuevos pods se crean autom√°ticamente
# - Despu√©s de 5 min sin carga, pods se reducen
```

---

## üß™ Pruebas de Validaci√≥n

### Test 1: Resource Limits Funcionan

```bash
# Ver l√≠mites aplicados
kubectl describe pod <pod-name> -n app-namespace | grep -A5 "Limits"

# Resultado esperado:
# Limits:
#   cpu:     500m
#   memory:  256Mi
# Requests:
#   cpu:        250m
#   memory:     128Mi
```

### Test 2: Health Checks Funcionan

```bash
# Simular pod con problemas (ejemplo: matar MySQL)
kubectl exec -it deployment/mysql -n app-namespace -- pkill mysqld

# Observar (en 30-60s):
kubectl get pods -n app-namespace
# php-app pods deber√≠an marcar como Not Ready
# Luego reiniciarse autom√°ticamente

# Ver eventos
kubectl get events -n app-namespace --sort-by='.lastTimestamp' | grep "Unhealthy\|Liveness\|Readiness"
```

### Test 3: HPA Escala Correctamente

```bash
# Ver estado inicial
kubectl get hpa php-app-hpa -n app-namespace

# Generar carga sostenida
ab -n 50000 -c 100 -t 300 http://localhost:8080/

# Monitorear escalado (cada 15s)
watch 'kubectl get hpa php-app-hpa -n app-namespace'

# Resultado esperado:
# TARGETS: 85%/70% (CPU sobre objetivo)
# REPLICAS: 3 ‚Üí 5 ‚Üí 7 ‚Üí (hasta 10)

# Detener carga y esperar 5 min
# REPLICAS: 7 ‚Üí 5 ‚Üí 3 (gradualmente)
```

---

## üìà M√©tricas de √âxito

### Antes de Optimizaciones

```bash
$ kubectl top pods -n app-namespace
NAME                       CPU(cores)   MEMORY(Mi)
php-app-xxxxx              720m         312Mi      ‚ùå Sin l√≠mite
php-app-yyyyy              680m         298Mi      ‚ùå Sin l√≠mite
php-app-zzzzz              695m         305Mi      ‚ùå Sin l√≠mite

$ ab -n 1000 -c 50 http://localhost:8080
Complete requests:      600            ‚ùå 40% fall√≥
Failed requests:        400
Time per request:       15000ms        ‚ùå Muy lento
```

### Despu√©s de Optimizaciones

```bash
$ kubectl top pods -n app-namespace
NAME                       CPU(cores)   MEMORY(Mi)
php-app-xxxxx              380m         180Mi      ‚úÖ Dentro de l√≠mite
php-app-yyyyy              420m         195Mi      ‚úÖ Dentro de l√≠mite
php-app-zzzzz              390m         175Mi      ‚úÖ Dentro de l√≠mite
php-app-wwwww              410m         188Mi      ‚úÖ HPA escal√≥
php-app-vvvvv              405m         182Mi      ‚úÖ HPA escal√≥

$ ab -n 1000 -c 50 http://localhost:8080
Complete requests:      950            ‚úÖ 95% √©xito
Failed requests:        50
Time per request:       3000ms         ‚úÖ 5x m√°s r√°pido
```

---

## üéØ Resumen de Comandos

```bash
# 1. Habilitar metrics
minikube addons enable metrics-server

# 2. Aplicar optimizaciones
kubectl apply -f kubernetes/deployment-optimized.yaml -n app-namespace

# 3. Verificar
kubectl get hpa -n app-namespace
kubectl describe pod <pod-name> -n app-namespace | grep -A10 "Liveness\|Readiness"
kubectl top pods -n app-namespace

# 4. Probar
ab -n 10000 -c 100 http://localhost:8080

# 5. Monitorear
watch 'kubectl get hpa,pods -n app-namespace'
```
